{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/writezubair-cpu/ZAK-TEST_AI_Training/blob/main/Copy_of_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a great request. Drawing on the uses cases mentioned in the video sources, I will focus on the example of **e-commerce product recommendations** and generate synthetic data and corresponding TensorFlow/Keras code.\n",
        "\n",
        "The sources highlight that TensorFlow is an open-source library created by Google used to **build, train, and deploy** machine learning models at a massive scale. For beginners or general developers, the recommended path is using **Keras**, the user-friendly, high-level API built right on top of TensorFlow. The Keras workflow is simply three steps: define, compile, and train.\n",
        "\n",
        "## 1. Synthetic Large Data Creation: E-commerce Product Recommendations\n",
        "\n",
        "E-commerce sites use TensorFlow for product recommendations. To model this, we will create a dataset representing user interactions (ratings) with products. Since the query asks for \"synthetic large data,\" we will generate 100,000 interaction records.\n",
        "\n",
        "*Note: While the source material focuses on TensorFlow and Keras, standard Python libraries like `numpy` and `pandas` (which are not explicitly mentioned in the sources) are required to generate and structure this large synthetic dataset.*\n",
        "\n",
        "### Use Case: Simplified Collaborative Filtering Model\n",
        "\n",
        "We simulate data based on:\n",
        "1.  **Number of Users:** 1,000\n",
        "2.  **Number of Products:** 500\n",
        "3.  **Total Interactions (Ratings):** 100,000\n"
      ],
      "metadata": {
        "id": "D3L5tbJcabR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define parameters for 'large' synthetic data\n",
        "NUM_USERS = 100000\n",
        "NUM_PRODUCTS = 50000\n",
        "NUM_INTERACTIONS = 100000\n",
        "\n",
        "# 1. Create Synthetic IDs\n",
        "# Generate a large array of random User IDs\n",
        "user_ids = np.random.randint(1, NUM_USERS + 1, NUM_INTERACTIONS)\n",
        "# Generate a large array of random Product IDs\n",
        "product_ids = np.random.randint(1, NUM_PRODUCTS + 1, NUM_INTERACTIONS)\n",
        "# Generate interaction ratings (e.g., 1 to 5 stars)\n",
        "ratings = np.random.randint(1, 6, NUM_INTERACTIONS)\n",
        "\n",
        "# 2. Structure the data into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'user_id': user_ids,\n",
        "    'product_id': product_ids,\n",
        "    'rating': ratings\n",
        "})\n",
        "\n",
        "# Display the size and a sample of the synthetic data\n",
        "print(f\"--- Synthetic Data for E-commerce Recommendations ---\")\n",
        "print(f\"Total Interactions Generated: {len(data)} (Large Scale Data)\")\n",
        "print(data.head())\n",
        "\n",
        "# 3. Prepare data for model training\n",
        "# Determine unique counts for embedding layers\n",
        "unique_users = data['user_id'].nunique()\n",
        "unique_products = data['product_id'].nunique()\n",
        "\n",
        "# Map IDs to contiguous integers starting from 0 (required for embeddings)\n",
        "user_map = {id: i for i, id in enumerate(data['user_id'].unique())}\n",
        "product_map = {id: i for i, id in enumerate(data['product_id'].unique())}\n",
        "\n",
        "data['user'] = data['user_id'].map(user_map)\n",
        "data['product'] = data['product_id'].map(product_map)\n",
        "\n",
        "# Define X (inputs) and y (target)\n",
        "X = data[['user', 'product']].values\n",
        "y = data['rating'].values\n",
        "\n",
        "# Split data into training and testing sets (standard preparation step)\n",
        "from sklearn.model_selection import train_test_split # Note: sklearn is not mentioned in sources\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract inputs for the model\n",
        "train_user_input = X_train[:, 0]\n",
        "train_product_input = X_train[:, 1]\n",
        "\n",
        "\n",
        "## 2. TensorFlow/Keras Code for the Recommendation Model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0hhYviyan7P",
        "outputId": "ed021d2f-fe91-4e29-df0a-bb930adc337f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Synthetic Data for E-commerce Recommendations ---\n",
            "Total Interactions Generated: 100000 (Large Scale Data)\n",
            "   user_id  product_id  rating\n",
            "0    36465       26953       1\n",
            "1     1266       24622       2\n",
            "2    47467        8086       4\n",
            "3    18693        3015       3\n",
            "4     4520        8444       5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n -- `Interactions grouped by raiting\")\n",
        "print(data.groupby(\"rating\").size())\n"
      ],
      "metadata": {
        "id": "nUbDHDbzEkA8",
        "outputId": "1843c6d4-67a2-4d4a-a2af-87ff59bd9cf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " -- `Interactions grouped by raiting\n",
            "rating\n",
            "1    20011\n",
            "2    20007\n",
            "3    20016\n",
            "4    19894\n",
            "5    20072\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "Y0A5YxsaaRuL",
        "outputId": "ef1dd490-92c1-460a-8f35-7e31f5b1c264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │  \u001b[38;5;34m3,153,900\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │  \u001b[38;5;34m2,165,700\u001b[0m │ product_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_flatten        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_flatten     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ product_embeddin… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ user_flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ product_flatten[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m12,928\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,153,900</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,165,700</span> │ product_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_flatten        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ product_flatten     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ product_embeddin… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ product_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,340,849\u001b[0m (20.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,340,849</span> (20.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,340,849\u001b[0m (20.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,340,849</span> (20.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Model Training...\n",
            "Epoch 1/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - loss: 5.0537 - mae: 1.8362 - val_loss: 2.0162 - val_mae: 1.2175\n",
            "Epoch 2/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 69ms/step - loss: 1.5063 - mae: 1.0182 - val_loss: 2.2426 - val_mae: 1.2796\n",
            "Epoch 3/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.6723 - mae: 0.6460 - val_loss: 2.6268 - val_mae: 1.3536\n",
            "Epoch 4/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.3459 - mae: 0.4409 - val_loss: 2.8657 - val_mae: 1.4029\n",
            "Epoch 5/5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 77ms/step - loss: 0.2201 - mae: 0.3536 - val_loss: 2.9513 - val_mae: 1.4192\n",
            "Model Training Complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Step 1: Define the Model (Stacking layers like Legos) ---\n",
        "\n",
        "# Define constants based on the synthetic data preparation\n",
        "EMBEDDING_SIZE = 50 # Dimension for the learned embeddings\n",
        "NUM_USERS = unique_users # Total number of unique users\n",
        "NUM_PRODUCTS = unique_products # Total number of unique products\n",
        "\n",
        "# 1. Input layers\n",
        "# Define the input layer for User IDs\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "# Define the input layer for Product IDs\n",
        "product_input = Input(shape=(1,), name='product_input')\n",
        "\n",
        "# 2. Embedding layers (The core of collaborative filtering)\n",
        "# Embedding layer for users\n",
        "user_embedding = Embedding(\n",
        "    input_dim=NUM_USERS,\n",
        "    output_dim=EMBEDDING_SIZE,\n",
        "    input_length=1,\n",
        "    name='user_embedding'\n",
        ")(user_input)\n",
        "\n",
        "# Flatten the user embedding\n",
        "user_vec = Flatten(name='user_flatten')(user_embedding)\n",
        "\n",
        "# Embedding layer for products\n",
        "product_embedding = Embedding(\n",
        "    input_dim=NUM_PRODUCTS,\n",
        "    output_dim=EMBEDDING_SIZE,\n",
        "    input_length=1,\n",
        "    name='product_embedding'\n",
        ")(product_input)\n",
        "\n",
        "# Flatten the product embedding\n",
        "product_vec = Flatten(name='product_flatten')(product_embedding)\n",
        "\n",
        "# 3. Combine and Predict\n",
        "# Concatenate user and product vectors\n",
        "concat = Concatenate()([user_vec, product_vec])\n",
        "\n",
        "# Add Dense layers (fully connected layers) to process the combined vector\n",
        "dense_1 = Dense(128, activation='relu')(concat)\n",
        "dense_2 = Dense(64, activation='relu')(dense_1)\n",
        "\n",
        "# Output layer: Predict the final rating (or interaction score)\n",
        "# Since ratings are 1-5, we use a sigmoid output scaled to the range 1-5\n",
        "output = Dense(1, activation='linear')(dense_2)\n",
        "\n",
        "# Create the final Model object using the inputs and output\n",
        "model = Model(inputs=[user_input, product_input], outputs=output)\n",
        "\n",
        "\n",
        "# --- Step 2: Compile the Model (Telling it how to learn) ---\n",
        "\n",
        "# We choose the Adam optimizer and Mean Squared Error loss (common for regression tasks like rating prediction)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error',\n",
        "    metrics=['mae'] # Mean Absolute Error for easier interpretability\n",
        ")\n",
        "\n",
        "# Print a summary of the model structure\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- Step 3: Train the Model (Calling the fit function) ---\n",
        "\n",
        "print(\"\\nStarting Model Training...\")\n",
        "# Calling fit() gives the data to TensorFlow, which handles the heavy lifting\n",
        "history = model.fit(\n",
        "    x=[train_user_input, train_product_input], # Training input data\n",
        "    y=y_train,                              # Training target data (ratings)\n",
        "    epochs=5,                               # Number of training iterations\n",
        "    batch_size=256,\n",
        "    verbose=1,\n",
        "    validation_split=0.1                    # Hold back 10% of training data for validation\n",
        ")\n",
        "\n",
        "print(\"Model Training Complete.\")\n",
        "\n",
        "# --- Post-Training Step: Prepare for Deployment ---\n",
        "# Once trained and validated (perhaps using TensorBoard for visualization),\n",
        "# the model can be optimized and prepared for deployment on devices using TFLite.\n",
        "# model.save('recommendation_model.h5')\n",
        "# # Then convert to TFLite format for efficient device deployment:\n",
        "# # converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# # tflite_model = converter.convert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
        "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n"
      ],
      "metadata": {
        "id": "-EotnR_NJMVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(probs)"
      ],
      "metadata": {
        "id": "aA__P93BLWI9",
        "outputId": "8beea6e9-652e-4a26-859b-a3e0aaa7410c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.9925e-01, 7.5487e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Final Evaluation on Unseen Test Data ---\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Unseen Test Set ---\")\n",
        "\n",
        "# Extract inputs for the model from X_test\n",
        "test_user_input = X_test[:, 0]\n",
        "test_product_input = X_test[:, 1]\n",
        "\n",
        "# The evaluation process assesses the performance of the trained model\n",
        "# on the independent dataset (X_test, y_test) that the model has never seen.\n",
        "results = model.evaluate(\n",
        "    x=[test_user_input, test_product_input], # Test input data\n",
        "    y=y_test,                                # Test target data\n",
        "    batch_size=256,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Extract and display the metrics defined during the compile step\n",
        "loss = results[0]\n",
        "mae = results[1] # Mean Absolute Error (the chosen evaluation metric)\n",
        "\n",
        "print(f\"Test Loss (Mean Squared Error): {loss:.4f}\")\n",
        "print(f\"Test Mean Absolute Error (MAE): {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "wajV_FMQbhan",
        "outputId": "665efa8c-3836-48c2-8f68-6192b70f3668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Evaluation on Unseen Test Set ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-596290845.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Extract inputs for the model from X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_user_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_product_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enhancing Understanding\n",
        "\n",
        "TensorFlow provides an entire ecosystem. If we were to continue this workflow:\n",
        "\n",
        "*   **Visualization:** While the model is training, we would typically use **TensorBoard** to visualize the accuracy and spot problems, acting as a dashboard to see the model's mind at work.\n",
        "*   **Deployment:** Once training is complete, the model would be optimized using **TensorFlow Lite (TFLite)**. TFLite specializes in making the powerful model super small and efficient so it can run on edge devices like smartphones or smart home gadgets, allowing the AI to run right on the device for speed and privacy.\n",
        "\n",
        "The Keras workflow—defining layers, compiling, and calling `fit`—is like using **Lego bricks** to build a structure. The Lego bricks are the layers (Input, Embedding, Dense), and the compiled model is the instruction manual telling the structure how to stand up and function (the optimizer and loss function). When you call `fit`, you are simply starting the building process with the training data."
      ],
      "metadata": {
        "id": "cpUXtiPGaV_v"
      }
    }
  ]
}